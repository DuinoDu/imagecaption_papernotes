## 2017

MAT: A Multimodal Attentive Translator for Image Captioning
https://arxiv.org/abs/1702.05658

Deep Reinforcement Learning-based Image Captioning with Embedding Reward
arxiv: https://arxiv.org/abs/1704.03899

Attend to You: Personalized Image Captioning with Context Sequence Memory Networks
arxiv: https://arxiv.org/abs/1704.06485
github: https://github.com/cesc-park/attend2u

Punny Captions: Witty Wordplay in Image Descriptions
https://arxiv.org/abs/1704.08224

Show, Adapt and Tell: Adversarial Training of Cross-domain Image Captioner
https://arxiv.org/abs/1705.00930

Actor-Critic Sequence Training for Image Captioning
keywords: actor-critic reinforcement learning
arxiv: https://arxiv.org/abs/1706.09601

What is the Role of Recurrent Neural Networks (RNNs) in an Image Caption Generator?
arxiv: https://arxiv.org/abs/1708.02043

Stack-Captioning: Coarse-to-Fine Learning for Image Captioning
https://arxiv.org/abs/1709.03376

Self-Guiding Multimodal LSTM - when we do not have a perfect training dataset for image captioning
https://arxiv.org/abs/1709.05038

## 2016

Multimodal Pivots for Image Caption Translation
arxiv: http://arxiv.org/abs/1601.03916

Image Captioning with Deep Bidirectional LSTMs
arxiv: http://arxiv.org/abs/1604.00790
github(Caffe): https://github.com/deepsemantic/image_captioning
demo: https://youtu.be/a0bh9_2LE24

Review Network for Caption Generation
arxiv: https://arxiv.org/abs/1605.07912
github: https://github.com/kimiyoung/review_net

Attention Correctness in Neural Image Captioning
arxiv: http://arxiv.org/abs/1605.09553

Image Caption Generation with Text-Conditional Semantic Attention
arxiv: https://arxiv.org/abs/1606.04621
github: https://github.com/LuoweiZhou/e2e-gLSTM-sc

DeepDiary: Automatic Caption Generation for Lifelogging Image Streams
arxiv: http://arxiv.org/abs/1608.03819

phi-LSTM: A Phrase-based Hierarchical LSTM Model for Image Captioning
arxiv: http://arxiv.org/abs/1608.05813

Captioning Images with Diverse Objects
arxiv: http://arxiv.org/abs/1606.07770

Learning to generalize to new compositions in image understanding
arxiv: http://arxiv.org/abs/1608.07639

Generating captions without looking beyond objects
arxiv: https://arxiv.org/abs/1610.03708

SPICE: Semantic Propositional Image Caption Evaluation
project page: http://www.panderson.me/spice/
paper: http://www.panderson.me/images/SPICE.pdf
github: https://github.com/peteanderson80/SPICE

Boosting Image Captioning with Attributes
arxiv: https://arxiv.org/abs/1611.01646

Bootstrap, Review, Decode: Using Out-of-Domain Textual Data to Improve Image Captioning
arxiv: https://arxiv.org/abs/1611.05321

A Hierarchical Approach for Generating Descriptive Image Paragraphs
arxiv: https://arxiv.org/abs/1611.06607

Dense Captioning with Joint Inference and Visual Context
arxiv: https://arxiv.org/abs/1611.06949

Optimization of image description metrics using policy gradient methods
arxiv: https://arxiv.org/abs/1612.00370

Areas of Attention for Image Captioning
arxiv: https://arxiv.org/abs/1612.01033

Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning
arxiv: https://arxiv.org/abs/1612.01887
github: https://github.com/jiasenlu/AdaptiveAttention

Recurrent Image Captioner: Describing Images with Spatial-Invariant Transformation and Attention Filtering
arxiv: https://arxiv.org/abs/1612.04949

Recurrent Highway Networks with Language CNN for Image Captioning
arxiv: https://arxiv.org/abs/1612.07086

Top-down Visual Saliency Guided by Captions
arxiv: https://arxiv.org/abs/1612.07360
github: https://github.com/VisionLearningGroup/caption-guided-saliency

## 2015
- Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge [paper](http://arxiv.org/abs/1609.06647) [tf](https://github.com/tensorflow/models/tree/master/im2txt)
- Mindâ€™s Eye: A Recurrent Visual Representation for Image Caption Generation [paper](http://www.cs.cmu.edu/~xinleic/papers/cvpr15_rnn.pdf)
- Deep Captioning with Multimodal Recurrent Neural Networks [paper](http://arxiv.org/abs/1412.6632) [tf](https://github.com/mjhucla/TF-mRNN)

Show, Attend and Tell: Neural Image Caption Generation with Visual Attention (ICML 2015)
[paper](http://arxiv.org/abs/1502.03044)
github: https://github.com/kelvinxu/arctic-captions
github: https://github.com/jazzsaxmafia/show_attend_and_tell.tensorflow
github(TensorFlow): https://github.com/yunjey/show-attend-and-tell-tensorflow
demo: http://www.cs.toronto.edu/~rkiros/abstract_captions.html

Automatically describing historic photographs
website: https://staff.fnwi.uva.nl/d.elliott/loc/

Learning like a Child: Fast Novel Visual Concept Learning from Sentence Descriptions of Images
arxiv: http://arxiv.org/abs/1504.06692
homepage: http://www.stat.ucla.edu/~junhua.mao/projects/child_learning.html
github: https://github.com/mjhucla/NVC-Dataset

What value do explicit high level concepts have in vision to language problems?
arxiv: http://arxiv.org/abs/1506.01144

Aligning where to see and what to tell: image caption with region-based attention and scene factorization
arxiv: http://arxiv.org/abs/1506.06272

Learning FRAME Models Using CNN Filters for Knowledge Visualization (CVPR 2015)
project page: http://www.stat.ucla.edu/~yang.lu/project/deepFrame/main.html
arxiv: http://arxiv.org/abs/1509.08379
code+data: http://www.stat.ucla.edu/~yang.lu/project/deepFrame/doc/deepFRAME_1.1.zip

Generating Images from Captions with Attention
arxiv: http://arxiv.org/abs/1511.02793
github: https://github.com/emansim/text2image
demo: http://www.cs.toronto.edu/~emansim/cap2im.html

Order-Embeddings of Images and Language
arxiv: http://arxiv.org/abs/1511.06361
github: https://github.com/ivendrov/order-embedding

DenseCap: Fully Convolutional Localization Networks for Dense Captioning
project page: http://cs.stanford.edu/people/karpathy/densecap/
arxiv: http://arxiv.org/abs/1511.07571
github(Torch): https://github.com/jcjohnson/densecap

Expressing an Image Stream with a Sequence of Natural Sentences
nips-page: http://papers.nips.cc/paper/5776-expressing-an-image-stream-with-a-sequence-of-natural-sentences
paper: http://papers.nips.cc/paper/5776-expressing-an-image-stream-with-a-sequence-of-natural-sentences.pdf
paper: http://www.cs.cmu.edu/~gunhee/publish/nips15_stream2text.pdf
author-page: http://www.cs.cmu.edu/~gunhee/
github: https://github.com/cesc-park/CRCN



## 2014
- Long-term Recurrent Convolutional Networks for Visual Recognition and Description [paper](http://arxiv.org/abs/1411.4389) [caffe](https://github.com/BVLC/caffe/pull/2033)
- Show and Tell: A Neural Image Caption Generator [paper](http://arxiv.org/abs/1411.4555) [tf](https://github.com/zsdonghao/Image-Captioning)
- Learning a Recurrent Visual Representation for Image Caption Generation [paper](http://arxiv.org/abs/1411.5654)
- Deep Visual-Semantic Alignments for Generating Image Descriptions [paper](http://arxiv.org/abs/1412.2306) [torch](http://arxiv.org/abs/1412.2306)


## 2013

## 2012

## 2011
- Im2Text: Describing Images Using 1 Million Captioned Photographs [paper](http://tamaraberg.com/papers/generation_nips2011.pdf)
