## 2017
- MAT: A Multimodal Attentive Translator for Image Captioning [paper](https://arxiv.org/abs/1702.05658)
- Deep Reinforcement Learning-based Image Captioning with Embedding Reward [paper](https://arxiv.org/abs/1704.03899)
- Attend to You: Personalized Image Captioning with Context Sequence Memory Networks [paper](https://arxiv.org/abs/1704.06485) [code](https://github.com/cesc-park/attend2u)
- Punny Captions: Witty Wordplay in Image Descriptions [paper](https://arxiv.org/abs/1704.08224)
- Show, Adapt and Tell: Adversarial Training of Cross-domain Image Captioner [paper](https://arxiv.org/abs/1705.00930)
- Actor-Critic Sequence Training for Image Captioning [paper](https://arxiv.org/abs/1706.09601)
- What is the Role of Recurrent Neural Networks (RNNs) in an Image Caption Generator? [paper](https://arxiv.org/abs/1708.02043)
- Stack-Captioning: Coarse-to-Fine Learning for Image Captioning [paper](https://arxiv.org/abs/1709.03376)
- Self-Guiding Multimodal LSTM - when we do not have a perfect training dataset for image captioning [paper](https://arxiv.org/abs/1709.05038)

## 2016
- Multimodal Pivots for Image Caption Translation [paper](http://arxiv.org/abs/1601.03916)
- Image Captioning with Deep Bidirectional LSTMs [paper](http://arxiv.org/abs/1604.00790) [code](https://github.com/deepsemantic/image_captioning)
- Review Network for Caption Generation [paper](https://arxiv.org/abs/1605.07912) [code](https://github.com/kimiyoung/review_net)
- Attention Correctness in Neural Image Captioning [paper](http://arxiv.org/abs/1605.09553)
- Image Caption Generation with Text-Conditional Semantic Attention [paper](https://arxiv.org/abs/1606.04621) [code](https://github.com/LuoweiZhou/e2e-gLSTM-sc)
- DeepDiary: Automatic Caption Generation for Lifelogging Image Streams [paper](http://arxiv.org/abs/1608.03819)
- phi-LSTM: A Phrase-based Hierarchical LSTM Model for Image Captioning [paper](http://arxiv.org/abs/1608.05813)
- Captioning Images with Diverse Objects [paper](http://arxiv.org/abs/1606.07770)
- Learning to generalize to new compositions in image understanding [paper](http://arxiv.org/abs/1608.07639)
- Generating captions without looking beyond objects [paper](https://arxiv.org/abs/1610.03708)
- SPICE: Semantic Propositional Image Caption Evaluation [paper](http://www.panderson.me/images/SPICE.pdf) [code](https://github.com/peteanderson80/SPICE)
- Boosting Image Captioning with Attributes [paper](https://arxiv.org/abs/1611.01646)
- Bootstrap, Review, Decode: Using Out-of-Domain Textual Data to Improve Image Captioning [paper](https://arxiv.org/abs/1611.05321)
- A Hierarchical Approach for Generating Descriptive Image Paragraphs [paper](https://arxiv.org/abs/1611.06607)
- Dense Captioning with Joint Inference and Visual Context [paper](https://arxiv.org/abs/1611.06949)
- Optimization of image description metrics using policy gradient methods [paper](https://arxiv.org/abs/1612.00370)
- Self-critical Sequence Training for Image Captioning [paper](https://arxiv.org/pdf/1612.00563.pdf) [pytorch](https://github.com/ruotianluo/self-critical.pytorch)
- Areas of Attention for Image Captioning [paper](https://arxiv.org/abs/1612.01033)
- Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning [paper](https://arxiv.org/abs/1612.01887) [code](https://github.com/jiasenlu/AdaptiveAttention)
- Recurrent Image Captioner: Describing Images with Spatial-Invariant Transformation and Attention Filtering [paper](https://arxiv.org/abs/1612.04949)
- Recurrent Highway Networks with Language CNN for Image Captioning [paper](https://arxiv.org/abs/1612.07086)
- Top-down Visual Saliency Guided by Captions [paper](https://arxiv.org/abs/1612.07360) [code](https://github.com/VisionLearningGroup/caption-guided-saliency)

## 2015 
- Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge [paper](http://arxiv.org/abs/1609.06647) [tf](https://github.com/tensorflow/models/tree/master/im2txt)
- Mindâ€™s Eye: A Recurrent Visual Representation for Image Caption Generation [paper](http://www.cs.cmu.edu/~xinleic/papers/cvpr15_rnn.pdf)
- Deep Captioning with Multimodal Recurrent Neural Networks [paper](http://arxiv.org/abs/1412.6632) [tf](https://github.com/mjhucla/TF-mRNN)
- Show, Attend and Tell: Neural Image Caption Generation with Visual Attention (ICML 2015) [paper](http://arxiv.org/abs/1502.03044) [code](https://github.com/kelvinxu/arctic-captions) [code](https://github.com/jazzsaxmafia/show_attend_and_tell.tensorflow) [code](https://github.com/yunjey/show-attend-and-tell-tensorflow) 
- Automatically describing historic photographs 
- Learning like a Child: Fast Novel Visual Concept Learning from Sentence Descriptions of Images [paper](http://arxiv.org/abs/1504.06692) [code](https://github.com/mjhucla/NVC-Dataset) 
- What value do explicit high level concepts have in vision to language problems? [paper](http://arxiv.org/abs/1506.01144) 
- Aligning where to see and what to tell: image caption with region-based attention and scene factorization [paper](http://arxiv.org/abs/1506.06272) 
- Learning FRAME Models Using CNN Filters for Knowledge Visualization (CVPR 2015) [paper](http://arxiv.org/abs/1509.08379) 
- Generating Images from Captions with Attention [paper](http://arxiv.org/abs/1511.02793) [code](https://github.com/emansim/text2image) 
- Order-Embeddings of Images and Language [paper](http://arxiv.org/abs/1511.06361) [code](https://github.com/ivendrov/order-embedding) 
- DenseCap: Fully Convolutional Localization Networks for Dense Captioning [paper](http://arxiv.org/abs/1511.07571) [code](https://github.com/jcjohnson/densecap) 
- Expressing an Image Stream with a Sequence of Natural Sentences [paper](http://papers.nips.cc/paper/5776-expressing-an-image-stream-with-a-sequence-of-natural-sentences) [paper](http://papers.nips.cc/paper/5776-expressing-an-image-stream-with-a-sequence-of-natural-sentences.pdf) [paper](http://www.cs.cmu.edu/~gunhee/publish/nips15_stream2text.pdf) [code](https://github.com/cesc-park/CRCN) 

## 2014
- Long-term Recurrent Convolutional Networks for Visual Recognition and Description [paper](http://arxiv.org/abs/1411.4389) [caffe](https://github.com/BVLC/caffe/pull/2033)
- Show and Tell: A Neural Image Caption Generator [paper](http://arxiv.org/abs/1411.4555) [tf](https://github.com/zsdonghao/Image-Captioning)
- Learning a Recurrent Visual Representation for Image Caption Generation [paper](http://arxiv.org/abs/1411.5654)
- Deep Visual-Semantic Alignments for Generating Image Descriptions [paper](http://arxiv.org/abs/1412.2306) [torch](http://arxiv.org/abs/1412.2306)


## 2013

## 2012

## 2011
- Im2Text: Describing Images Using 1 Million Captioned Photographs [paper](http://tamaraberg.com/papers/generation_nips2011.pdf)
